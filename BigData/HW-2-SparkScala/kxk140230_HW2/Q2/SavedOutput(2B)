Last login: Thu Oct 15 23:44:26 on ttys000
kanikas-MacBook-Pro:~ kanikakapoor$ ssh kxk140230@cs6360.utdallas.edu

                 Department of Computer Science
                 University of Texas at Dallas

  Pursuant to Texas Administrative Code 202:

  (1) Unauthorized use is prohibited;

  (2) Usage may be subject to security testing and monitoring;

  (3) Misuse is subject to criminal prosecution; and

  (4) No expectation of privacy except as otherwise provided by
      applicable privacy laws.


kxk140230@cs6360.utdallas.edu's password: 
Last login: Thu Oct 15 23:44:51 2015 from 10.21.74.218
Sourcing /usr/local/etc/skel/global/profile
-bash: rt: command not found
{cs6360:~} spark-shell --master yarn-client --executor-memory 2G --executor-cores 6 --num-executors 6 
Spark assembly has been built with Hive, including Datanucleus jars on classpath
15/10/15 23:48:00 INFO spark.SecurityManager: Changing view acls to: kxk140230
15/10/15 23:48:00 INFO spark.SecurityManager: Changing modify acls to: kxk140230
15/10/15 23:48:00 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(kxk140230); users with modify permissions: Set(kxk140230)
15/10/15 23:48:00 INFO spark.HttpServer: Starting HTTP Server
15/10/15 23:48:01 INFO server.Server: jetty-8.y.z-SNAPSHOT
15/10/15 23:48:01 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:35212
15/10/15 23:48:01 INFO util.Utils: Successfully started service 'HTTP class server' on port 35212.
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 1.2.0
      /_/

Using Scala version 2.10.4 (Java HotSpot(TM) 64-Bit Server VM, Java 1.7.0_51)
Type in expressions to have them evaluated.
Type :help for more information.
15/10/15 23:48:08 INFO spark.SecurityManager: Changing view acls to: kxk140230
15/10/15 23:48:08 INFO spark.SecurityManager: Changing modify acls to: kxk140230
15/10/15 23:48:08 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(kxk140230); users with modify permissions: Set(kxk140230)
15/10/15 23:48:09 INFO slf4j.Slf4jLogger: Slf4jLogger started
15/10/15 23:48:09 INFO Remoting: Starting remoting
15/10/15 23:48:09 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@cs6360.utdallas.edu:50946]
15/10/15 23:48:09 INFO util.Utils: Successfully started service 'sparkDriver' on port 50946.
15/10/15 23:48:09 INFO spark.SparkEnv: Registering MapOutputTracker
15/10/15 23:48:09 INFO spark.SparkEnv: Registering BlockManagerMaster
15/10/15 23:48:09 INFO storage.DiskBlockManager: Created local directory at /tmp/spark-local-20151015234809-05fe
15/10/15 23:48:09 INFO storage.MemoryStore: MemoryStore started with capacity 265.4 MB
15/10/15 23:48:10 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/10/15 23:48:10 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-eabe7a43-0d6e-4c2a-aa8c-5ba5ef435a95
15/10/15 23:48:10 INFO spark.HttpServer: Starting HTTP Server
15/10/15 23:48:10 INFO server.Server: jetty-8.y.z-SNAPSHOT
15/10/15 23:48:10 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:34482
15/10/15 23:48:10 INFO util.Utils: Successfully started service 'HTTP file server' on port 34482.
15/10/15 23:48:11 INFO server.Server: jetty-8.y.z-SNAPSHOT
15/10/15 23:48:11 WARN component.AbstractLifeCycle: FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:444)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:194)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1676)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1667)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:204)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:102)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:269)
	at org.apache.spark.repl.SparkILoop.createSparkContext(SparkILoop.scala:986)
	at $line3.$read$$iwC$$iwC.<init>(<console>:9)
	at $line3.$read$$iwC.<init>(<console>:18)
	at $line3.$read.<init>(<console>:20)
	at $line3.$read$.<init>(<console>:24)
	at $line3.$read$.<clinit>(<console>)
	at $line3.$eval$.<init>(<console>:7)
	at $line3.$eval$.<clinit>(<console>)
	at $line3.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:852)
	at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1125)
	at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:674)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:705)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:669)
	at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:828)
	at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:873)
	at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:785)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:123)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkIMain.beQuietDuring(SparkIMain.scala:270)
	at org.apache.spark.repl.SparkILoopInit$class.initializeSpark(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1$$anonfun$apply$mcZ$sp$5.apply$mcV$sp(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoopInit$class.runThunks(SparkILoopInit.scala:147)
	at org.apache.spark.repl.SparkILoop.runThunks(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoopInit$class.postInitialization(SparkILoopInit.scala:106)
	at org.apache.spark.repl.SparkILoop.postInitialization(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply$mcZ$sp(SparkILoop.scala:962)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1011)
	at org.apache.spark.repl.Main$.main(Main.scala:31)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:358)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
15/10/15 23:48:11 WARN component.AbstractLifeCycle: FAILED org.eclipse.jetty.server.Server@2ee4121e: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:444)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:194)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1676)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1667)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:204)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:102)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:269)
	at org.apache.spark.repl.SparkILoop.createSparkContext(SparkILoop.scala:986)
	at $line3.$read$$iwC$$iwC.<init>(<console>:9)
	at $line3.$read$$iwC.<init>(<console>:18)
	at $line3.$read.<init>(<console>:20)
	at $line3.$read$.<init>(<console>:24)
	at $line3.$read$.<clinit>(<console>)
	at $line3.$eval$.<init>(<console>:7)
	at $line3.$eval$.<clinit>(<console>)
	at $line3.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:852)
	at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1125)
	at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:674)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:705)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:669)
	at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:828)
	at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:873)
	at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:785)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:123)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkIMain.beQuietDuring(SparkIMain.scala:270)
	at org.apache.spark.repl.SparkILoopInit$class.initializeSpark(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1$$anonfun$apply$mcZ$sp$5.apply$mcV$sp(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoopInit$class.runThunks(SparkILoopInit.scala:147)
	at org.apache.spark.repl.SparkILoop.runThunks(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoopInit$class.postInitialization(SparkILoopInit.scala:106)
	at org.apache.spark.repl.SparkILoop.postInitialization(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply$mcZ$sp(SparkILoop.scala:962)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1011)
	at org.apache.spark.repl.Main$.main(Main.scala:31)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:358)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/static,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/threadDump/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/threadDump,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/job/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/job,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs,null}
15/10/15 23:48:11 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
15/10/15 23:48:11 INFO server.Server: jetty-8.y.z-SNAPSHOT
15/10/15 23:48:11 WARN component.AbstractLifeCycle: FAILED SelectChannelConnector@0.0.0.0:4041: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:444)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:194)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1676)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1667)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:204)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:102)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:269)
	at org.apache.spark.repl.SparkILoop.createSparkContext(SparkILoop.scala:986)
	at $line3.$read$$iwC$$iwC.<init>(<console>:9)
	at $line3.$read$$iwC.<init>(<console>:18)
	at $line3.$read.<init>(<console>:20)
	at $line3.$read$.<init>(<console>:24)
	at $line3.$read$.<clinit>(<console>)
	at $line3.$eval$.<init>(<console>:7)
	at $line3.$eval$.<clinit>(<console>)
	at $line3.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:852)
	at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1125)
	at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:674)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:705)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:669)
	at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:828)
	at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:873)
	at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:785)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:123)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkIMain.beQuietDuring(SparkIMain.scala:270)
	at org.apache.spark.repl.SparkILoopInit$class.initializeSpark(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1$$anonfun$apply$mcZ$sp$5.apply$mcV$sp(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoopInit$class.runThunks(SparkILoopInit.scala:147)
	at org.apache.spark.repl.SparkILoop.runThunks(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoopInit$class.postInitialization(SparkILoopInit.scala:106)
	at org.apache.spark.repl.SparkILoop.postInitialization(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply$mcZ$sp(SparkILoop.scala:962)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1011)
	at org.apache.spark.repl.Main$.main(Main.scala:31)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:358)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
15/10/15 23:48:11 WARN component.AbstractLifeCycle: FAILED org.eclipse.jetty.server.Server@2a5613b9: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:444)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:194)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1676)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1667)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:204)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:102)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:269)
	at org.apache.spark.repl.SparkILoop.createSparkContext(SparkILoop.scala:986)
	at $line3.$read$$iwC$$iwC.<init>(<console>:9)
	at $line3.$read$$iwC.<init>(<console>:18)
	at $line3.$read.<init>(<console>:20)
	at $line3.$read$.<init>(<console>:24)
	at $line3.$read$.<clinit>(<console>)
	at $line3.$eval$.<init>(<console>:7)
	at $line3.$eval$.<clinit>(<console>)
	at $line3.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:852)
	at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1125)
	at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:674)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:705)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:669)
	at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:828)
	at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:873)
	at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:785)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:123)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkIMain.beQuietDuring(SparkIMain.scala:270)
	at org.apache.spark.repl.SparkILoopInit$class.initializeSpark(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1$$anonfun$apply$mcZ$sp$5.apply$mcV$sp(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoopInit$class.runThunks(SparkILoopInit.scala:147)
	at org.apache.spark.repl.SparkILoop.runThunks(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoopInit$class.postInitialization(SparkILoopInit.scala:106)
	at org.apache.spark.repl.SparkILoop.postInitialization(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply$mcZ$sp(SparkILoop.scala:962)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1011)
	at org.apache.spark.repl.Main$.main(Main.scala:31)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:358)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/static,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/threadDump/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/threadDump,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/job/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/job,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs,null}
15/10/15 23:48:11 WARN util.Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
15/10/15 23:48:11 INFO server.Server: jetty-8.y.z-SNAPSHOT
15/10/15 23:48:11 WARN component.AbstractLifeCycle: FAILED SelectChannelConnector@0.0.0.0:4042: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:444)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:194)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1676)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1667)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:204)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:102)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:269)
	at org.apache.spark.repl.SparkILoop.createSparkContext(SparkILoop.scala:986)
	at $line3.$read$$iwC$$iwC.<init>(<console>:9)
	at $line3.$read$$iwC.<init>(<console>:18)
	at $line3.$read.<init>(<console>:20)
	at $line3.$read$.<init>(<console>:24)
	at $line3.$read$.<clinit>(<console>)
	at $line3.$eval$.<init>(<console>:7)
	at $line3.$eval$.<clinit>(<console>)
	at $line3.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:852)
	at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1125)
	at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:674)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:705)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:669)
	at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:828)
	at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:873)
	at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:785)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:123)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkIMain.beQuietDuring(SparkIMain.scala:270)
	at org.apache.spark.repl.SparkILoopInit$class.initializeSpark(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1$$anonfun$apply$mcZ$sp$5.apply$mcV$sp(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoopInit$class.runThunks(SparkILoopInit.scala:147)
	at org.apache.spark.repl.SparkILoop.runThunks(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoopInit$class.postInitialization(SparkILoopInit.scala:106)
	at org.apache.spark.repl.SparkILoop.postInitialization(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply$mcZ$sp(SparkILoop.scala:962)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1011)
	at org.apache.spark.repl.Main$.main(Main.scala:31)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:358)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
15/10/15 23:48:11 WARN component.AbstractLifeCycle: FAILED org.eclipse.jetty.server.Server@78bc1b9c: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:444)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:194)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1676)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1667)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:204)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:102)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:269)
	at org.apache.spark.repl.SparkILoop.createSparkContext(SparkILoop.scala:986)
	at $line3.$read$$iwC$$iwC.<init>(<console>:9)
	at $line3.$read$$iwC.<init>(<console>:18)
	at $line3.$read.<init>(<console>:20)
	at $line3.$read$.<init>(<console>:24)
	at $line3.$read$.<clinit>(<console>)
	at $line3.$eval$.<init>(<console>:7)
	at $line3.$eval$.<clinit>(<console>)
	at $line3.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:852)
	at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1125)
	at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:674)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:705)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:669)
	at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:828)
	at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:873)
	at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:785)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:123)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkIMain.beQuietDuring(SparkIMain.scala:270)
	at org.apache.spark.repl.SparkILoopInit$class.initializeSpark(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1$$anonfun$apply$mcZ$sp$5.apply$mcV$sp(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoopInit$class.runThunks(SparkILoopInit.scala:147)
	at org.apache.spark.repl.SparkILoop.runThunks(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoopInit$class.postInitialization(SparkILoopInit.scala:106)
	at org.apache.spark.repl.SparkILoop.postInitialization(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply$mcZ$sp(SparkILoop.scala:962)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1011)
	at org.apache.spark.repl.Main$.main(Main.scala:31)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:358)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/static,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/threadDump/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/threadDump,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/job/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/job,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs,null}
15/10/15 23:48:11 WARN util.Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
15/10/15 23:48:11 INFO server.Server: jetty-8.y.z-SNAPSHOT
15/10/15 23:48:11 WARN component.AbstractLifeCycle: FAILED SelectChannelConnector@0.0.0.0:4043: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:444)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:194)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1676)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1667)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:204)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:102)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:269)
	at org.apache.spark.repl.SparkILoop.createSparkContext(SparkILoop.scala:986)
	at $line3.$read$$iwC$$iwC.<init>(<console>:9)
	at $line3.$read$$iwC.<init>(<console>:18)
	at $line3.$read.<init>(<console>:20)
	at $line3.$read$.<init>(<console>:24)
	at $line3.$read$.<clinit>(<console>)
	at $line3.$eval$.<init>(<console>:7)
	at $line3.$eval$.<clinit>(<console>)
	at $line3.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:852)
	at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1125)
	at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:674)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:705)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:669)
	at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:828)
	at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:873)
	at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:785)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:123)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkIMain.beQuietDuring(SparkIMain.scala:270)
	at org.apache.spark.repl.SparkILoopInit$class.initializeSpark(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1$$anonfun$apply$mcZ$sp$5.apply$mcV$sp(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoopInit$class.runThunks(SparkILoopInit.scala:147)
	at org.apache.spark.repl.SparkILoop.runThunks(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoopInit$class.postInitialization(SparkILoopInit.scala:106)
	at org.apache.spark.repl.SparkILoop.postInitialization(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply$mcZ$sp(SparkILoop.scala:962)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1011)
	at org.apache.spark.repl.Main$.main(Main.scala:31)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:358)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
15/10/15 23:48:11 WARN component.AbstractLifeCycle: FAILED org.eclipse.jetty.server.Server@7a716adf: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:444)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:194)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1676)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1667)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:204)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:102)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:269)
	at org.apache.spark.repl.SparkILoop.createSparkContext(SparkILoop.scala:986)
	at $line3.$read$$iwC$$iwC.<init>(<console>:9)
	at $line3.$read$$iwC.<init>(<console>:18)
	at $line3.$read.<init>(<console>:20)
	at $line3.$read$.<init>(<console>:24)
	at $line3.$read$.<clinit>(<console>)
	at $line3.$eval$.<init>(<console>:7)
	at $line3.$eval$.<clinit>(<console>)
	at $line3.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:852)
	at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1125)
	at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:674)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:705)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:669)
	at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:828)
	at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:873)
	at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:785)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:123)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkIMain.beQuietDuring(SparkIMain.scala:270)
	at org.apache.spark.repl.SparkILoopInit$class.initializeSpark(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1$$anonfun$apply$mcZ$sp$5.apply$mcV$sp(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoopInit$class.runThunks(SparkILoopInit.scala:147)
	at org.apache.spark.repl.SparkILoop.runThunks(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoopInit$class.postInitialization(SparkILoopInit.scala:106)
	at org.apache.spark.repl.SparkILoop.postInitialization(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply$mcZ$sp(SparkILoop.scala:962)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1011)
	at org.apache.spark.repl.Main$.main(Main.scala:31)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:358)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/static,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/threadDump/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/threadDump,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/job/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/job,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs,null}
15/10/15 23:48:11 WARN util.Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
15/10/15 23:48:11 INFO server.Server: jetty-8.y.z-SNAPSHOT
15/10/15 23:48:11 WARN component.AbstractLifeCycle: FAILED SelectChannelConnector@0.0.0.0:4044: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:444)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:194)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1676)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1667)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:204)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:102)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:269)
	at org.apache.spark.repl.SparkILoop.createSparkContext(SparkILoop.scala:986)
	at $line3.$read$$iwC$$iwC.<init>(<console>:9)
	at $line3.$read$$iwC.<init>(<console>:18)
	at $line3.$read.<init>(<console>:20)
	at $line3.$read$.<init>(<console>:24)
	at $line3.$read$.<clinit>(<console>)
	at $line3.$eval$.<init>(<console>:7)
	at $line3.$eval$.<clinit>(<console>)
	at $line3.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:852)
	at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1125)
	at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:674)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:705)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:669)
	at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:828)
	at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:873)
	at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:785)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:123)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkIMain.beQuietDuring(SparkIMain.scala:270)
	at org.apache.spark.repl.SparkILoopInit$class.initializeSpark(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1$$anonfun$apply$mcZ$sp$5.apply$mcV$sp(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoopInit$class.runThunks(SparkILoopInit.scala:147)
	at org.apache.spark.repl.SparkILoop.runThunks(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoopInit$class.postInitialization(SparkILoopInit.scala:106)
	at org.apache.spark.repl.SparkILoop.postInitialization(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply$mcZ$sp(SparkILoop.scala:962)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1011)
	at org.apache.spark.repl.Main$.main(Main.scala:31)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:358)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
15/10/15 23:48:11 WARN component.AbstractLifeCycle: FAILED org.eclipse.jetty.server.Server@7bde88f5: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:444)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:194)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1676)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1667)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:204)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:102)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:269)
	at org.apache.spark.repl.SparkILoop.createSparkContext(SparkILoop.scala:986)
	at $line3.$read$$iwC$$iwC.<init>(<console>:9)
	at $line3.$read$$iwC.<init>(<console>:18)
	at $line3.$read.<init>(<console>:20)
	at $line3.$read$.<init>(<console>:24)
	at $line3.$read$.<clinit>(<console>)
	at $line3.$eval$.<init>(<console>:7)
	at $line3.$eval$.<clinit>(<console>)
	at $line3.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:852)
	at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1125)
	at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:674)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:705)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:669)
	at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:828)
	at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:873)
	at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:785)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:123)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkIMain.beQuietDuring(SparkIMain.scala:270)
	at org.apache.spark.repl.SparkILoopInit$class.initializeSpark(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1$$anonfun$apply$mcZ$sp$5.apply$mcV$sp(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoopInit$class.runThunks(SparkILoopInit.scala:147)
	at org.apache.spark.repl.SparkILoop.runThunks(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoopInit$class.postInitialization(SparkILoopInit.scala:106)
	at org.apache.spark.repl.SparkILoop.postInitialization(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply$mcZ$sp(SparkILoop.scala:962)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1011)
	at org.apache.spark.repl.Main$.main(Main.scala:31)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:358)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/static,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/threadDump/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/threadDump,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/job/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/job,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs,null}
15/10/15 23:48:11 WARN util.Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.
15/10/15 23:48:11 INFO server.Server: jetty-8.y.z-SNAPSHOT
15/10/15 23:48:11 WARN component.AbstractLifeCycle: FAILED SelectChannelConnector@0.0.0.0:4045: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:444)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:194)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1676)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1667)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:204)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:102)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:269)
	at org.apache.spark.repl.SparkILoop.createSparkContext(SparkILoop.scala:986)
	at $line3.$read$$iwC$$iwC.<init>(<console>:9)
	at $line3.$read$$iwC.<init>(<console>:18)
	at $line3.$read.<init>(<console>:20)
	at $line3.$read$.<init>(<console>:24)
	at $line3.$read$.<clinit>(<console>)
	at $line3.$eval$.<init>(<console>:7)
	at $line3.$eval$.<clinit>(<console>)
	at $line3.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:852)
	at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1125)
	at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:674)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:705)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:669)
	at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:828)
	at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:873)
	at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:785)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:123)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkIMain.beQuietDuring(SparkIMain.scala:270)
	at org.apache.spark.repl.SparkILoopInit$class.initializeSpark(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1$$anonfun$apply$mcZ$sp$5.apply$mcV$sp(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoopInit$class.runThunks(SparkILoopInit.scala:147)
	at org.apache.spark.repl.SparkILoop.runThunks(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoopInit$class.postInitialization(SparkILoopInit.scala:106)
	at org.apache.spark.repl.SparkILoop.postInitialization(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply$mcZ$sp(SparkILoop.scala:962)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1011)
	at org.apache.spark.repl.Main$.main(Main.scala:31)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:358)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
15/10/15 23:48:11 WARN component.AbstractLifeCycle: FAILED org.eclipse.jetty.server.Server@37dbb38f: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:444)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:194)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1676)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1667)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:204)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:102)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:269)
	at org.apache.spark.repl.SparkILoop.createSparkContext(SparkILoop.scala:986)
	at $line3.$read$$iwC$$iwC.<init>(<console>:9)
	at $line3.$read$$iwC.<init>(<console>:18)
	at $line3.$read.<init>(<console>:20)
	at $line3.$read$.<init>(<console>:24)
	at $line3.$read$.<clinit>(<console>)
	at $line3.$eval$.<init>(<console>:7)
	at $line3.$eval$.<clinit>(<console>)
	at $line3.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:852)
	at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1125)
	at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:674)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:705)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:669)
	at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:828)
	at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:873)
	at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:785)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:123)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkIMain.beQuietDuring(SparkIMain.scala:270)
	at org.apache.spark.repl.SparkILoopInit$class.initializeSpark(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1$$anonfun$apply$mcZ$sp$5.apply$mcV$sp(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoopInit$class.runThunks(SparkILoopInit.scala:147)
	at org.apache.spark.repl.SparkILoop.runThunks(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoopInit$class.postInitialization(SparkILoopInit.scala:106)
	at org.apache.spark.repl.SparkILoop.postInitialization(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply$mcZ$sp(SparkILoop.scala:962)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1011)
	at org.apache.spark.repl.Main$.main(Main.scala:31)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:358)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/static,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/threadDump/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/threadDump,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/job/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/job,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs,null}
15/10/15 23:48:11 WARN util.Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.
15/10/15 23:48:11 INFO server.Server: jetty-8.y.z-SNAPSHOT
15/10/15 23:48:11 WARN component.AbstractLifeCycle: FAILED SelectChannelConnector@0.0.0.0:4046: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:444)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:194)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1676)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1667)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:204)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:102)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:269)
	at org.apache.spark.repl.SparkILoop.createSparkContext(SparkILoop.scala:986)
	at $line3.$read$$iwC$$iwC.<init>(<console>:9)
	at $line3.$read$$iwC.<init>(<console>:18)
	at $line3.$read.<init>(<console>:20)
	at $line3.$read$.<init>(<console>:24)
	at $line3.$read$.<clinit>(<console>)
	at $line3.$eval$.<init>(<console>:7)
	at $line3.$eval$.<clinit>(<console>)
	at $line3.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:852)
	at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1125)
	at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:674)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:705)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:669)
	at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:828)
	at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:873)
	at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:785)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:123)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkIMain.beQuietDuring(SparkIMain.scala:270)
	at org.apache.spark.repl.SparkILoopInit$class.initializeSpark(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1$$anonfun$apply$mcZ$sp$5.apply$mcV$sp(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoopInit$class.runThunks(SparkILoopInit.scala:147)
	at org.apache.spark.repl.SparkILoop.runThunks(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoopInit$class.postInitialization(SparkILoopInit.scala:106)
	at org.apache.spark.repl.SparkILoop.postInitialization(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply$mcZ$sp(SparkILoop.scala:962)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1011)
	at org.apache.spark.repl.Main$.main(Main.scala:31)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:358)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
15/10/15 23:48:11 WARN component.AbstractLifeCycle: FAILED org.eclipse.jetty.server.Server@7c1a5bc2: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:444)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:194)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1676)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1667)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:204)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:102)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:269)
	at org.apache.spark.repl.SparkILoop.createSparkContext(SparkILoop.scala:986)
	at $line3.$read$$iwC$$iwC.<init>(<console>:9)
	at $line3.$read$$iwC.<init>(<console>:18)
	at $line3.$read.<init>(<console>:20)
	at $line3.$read$.<init>(<console>:24)
	at $line3.$read$.<clinit>(<console>)
	at $line3.$eval$.<init>(<console>:7)
	at $line3.$eval$.<clinit>(<console>)
	at $line3.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:852)
	at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1125)
	at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:674)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:705)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:669)
	at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:828)
	at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:873)
	at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:785)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:123)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkIMain.beQuietDuring(SparkIMain.scala:270)
	at org.apache.spark.repl.SparkILoopInit$class.initializeSpark(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1$$anonfun$apply$mcZ$sp$5.apply$mcV$sp(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoopInit$class.runThunks(SparkILoopInit.scala:147)
	at org.apache.spark.repl.SparkILoop.runThunks(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoopInit$class.postInitialization(SparkILoopInit.scala:106)
	at org.apache.spark.repl.SparkILoop.postInitialization(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply$mcZ$sp(SparkILoop.scala:962)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1011)
	at org.apache.spark.repl.Main$.main(Main.scala:31)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:358)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/static,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/threadDump/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/threadDump,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/job/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/job,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs,null}
15/10/15 23:48:11 WARN util.Utils: Service 'SparkUI' could not bind on port 4046. Attempting port 4047.
15/10/15 23:48:11 INFO server.Server: jetty-8.y.z-SNAPSHOT
15/10/15 23:48:11 WARN component.AbstractLifeCycle: FAILED SelectChannelConnector@0.0.0.0:4047: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:444)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:194)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1676)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1667)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:204)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:102)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:269)
	at org.apache.spark.repl.SparkILoop.createSparkContext(SparkILoop.scala:986)
	at $line3.$read$$iwC$$iwC.<init>(<console>:9)
	at $line3.$read$$iwC.<init>(<console>:18)
	at $line3.$read.<init>(<console>:20)
	at $line3.$read$.<init>(<console>:24)
	at $line3.$read$.<clinit>(<console>)
	at $line3.$eval$.<init>(<console>:7)
	at $line3.$eval$.<clinit>(<console>)
	at $line3.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:852)
	at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1125)
	at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:674)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:705)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:669)
	at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:828)
	at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:873)
	at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:785)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:123)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkIMain.beQuietDuring(SparkIMain.scala:270)
	at org.apache.spark.repl.SparkILoopInit$class.initializeSpark(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1$$anonfun$apply$mcZ$sp$5.apply$mcV$sp(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoopInit$class.runThunks(SparkILoopInit.scala:147)
	at org.apache.spark.repl.SparkILoop.runThunks(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoopInit$class.postInitialization(SparkILoopInit.scala:106)
	at org.apache.spark.repl.SparkILoop.postInitialization(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply$mcZ$sp(SparkILoop.scala:962)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1011)
	at org.apache.spark.repl.Main$.main(Main.scala:31)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:358)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
15/10/15 23:48:11 WARN component.AbstractLifeCycle: FAILED org.eclipse.jetty.server.Server@122779bc: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:444)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:194)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1676)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1667)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:204)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:102)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:269)
	at org.apache.spark.repl.SparkILoop.createSparkContext(SparkILoop.scala:986)
	at $line3.$read$$iwC$$iwC.<init>(<console>:9)
	at $line3.$read$$iwC.<init>(<console>:18)
	at $line3.$read.<init>(<console>:20)
	at $line3.$read$.<init>(<console>:24)
	at $line3.$read$.<clinit>(<console>)
	at $line3.$eval$.<init>(<console>:7)
	at $line3.$eval$.<clinit>(<console>)
	at $line3.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:852)
	at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1125)
	at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:674)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:705)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:669)
	at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:828)
	at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:873)
	at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:785)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:123)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkIMain.beQuietDuring(SparkIMain.scala:270)
	at org.apache.spark.repl.SparkILoopInit$class.initializeSpark(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1$$anonfun$apply$mcZ$sp$5.apply$mcV$sp(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoopInit$class.runThunks(SparkILoopInit.scala:147)
	at org.apache.spark.repl.SparkILoop.runThunks(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoopInit$class.postInitialization(SparkILoopInit.scala:106)
	at org.apache.spark.repl.SparkILoop.postInitialization(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply$mcZ$sp(SparkILoop.scala:962)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1011)
	at org.apache.spark.repl.Main$.main(Main.scala:31)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:358)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/static,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/threadDump/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/threadDump,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/job/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/job,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs,null}
15/10/15 23:48:11 WARN util.Utils: Service 'SparkUI' could not bind on port 4047. Attempting port 4048.
15/10/15 23:48:11 INFO server.Server: jetty-8.y.z-SNAPSHOT
15/10/15 23:48:11 WARN component.AbstractLifeCycle: FAILED SelectChannelConnector@0.0.0.0:4048: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:444)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:194)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1676)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1667)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:204)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:102)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:269)
	at org.apache.spark.repl.SparkILoop.createSparkContext(SparkILoop.scala:986)
	at $line3.$read$$iwC$$iwC.<init>(<console>:9)
	at $line3.$read$$iwC.<init>(<console>:18)
	at $line3.$read.<init>(<console>:20)
	at $line3.$read$.<init>(<console>:24)
	at $line3.$read$.<clinit>(<console>)
	at $line3.$eval$.<init>(<console>:7)
	at $line3.$eval$.<clinit>(<console>)
	at $line3.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:852)
	at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1125)
	at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:674)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:705)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:669)
	at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:828)
	at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:873)
	at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:785)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:123)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkIMain.beQuietDuring(SparkIMain.scala:270)
	at org.apache.spark.repl.SparkILoopInit$class.initializeSpark(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1$$anonfun$apply$mcZ$sp$5.apply$mcV$sp(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoopInit$class.runThunks(SparkILoopInit.scala:147)
	at org.apache.spark.repl.SparkILoop.runThunks(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoopInit$class.postInitialization(SparkILoopInit.scala:106)
	at org.apache.spark.repl.SparkILoop.postInitialization(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply$mcZ$sp(SparkILoop.scala:962)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1011)
	at org.apache.spark.repl.Main$.main(Main.scala:31)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:358)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
15/10/15 23:48:11 WARN component.AbstractLifeCycle: FAILED org.eclipse.jetty.server.Server@6ae9d641: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:444)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:194)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1676)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1667)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:204)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:102)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:269)
	at org.apache.spark.repl.SparkILoop.createSparkContext(SparkILoop.scala:986)
	at $line3.$read$$iwC$$iwC.<init>(<console>:9)
	at $line3.$read$$iwC.<init>(<console>:18)
	at $line3.$read.<init>(<console>:20)
	at $line3.$read$.<init>(<console>:24)
	at $line3.$read$.<clinit>(<console>)
	at $line3.$eval$.<init>(<console>:7)
	at $line3.$eval$.<clinit>(<console>)
	at $line3.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:852)
	at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1125)
	at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:674)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:705)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:669)
	at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:828)
	at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:873)
	at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:785)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:123)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkIMain.beQuietDuring(SparkIMain.scala:270)
	at org.apache.spark.repl.SparkILoopInit$class.initializeSpark(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1$$anonfun$apply$mcZ$sp$5.apply$mcV$sp(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoopInit$class.runThunks(SparkILoopInit.scala:147)
	at org.apache.spark.repl.SparkILoop.runThunks(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoopInit$class.postInitialization(SparkILoopInit.scala:106)
	at org.apache.spark.repl.SparkILoop.postInitialization(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply$mcZ$sp(SparkILoop.scala:962)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1011)
	at org.apache.spark.repl.Main$.main(Main.scala:31)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:358)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/static,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/threadDump/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/threadDump,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/job/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/job,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs,null}
15/10/15 23:48:11 WARN util.Utils: Service 'SparkUI' could not bind on port 4048. Attempting port 4049.
15/10/15 23:48:11 INFO server.Server: jetty-8.y.z-SNAPSHOT
15/10/15 23:48:11 WARN component.AbstractLifeCycle: FAILED SelectChannelConnector@0.0.0.0:4049: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:444)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:194)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1676)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1667)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:204)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:102)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:269)
	at org.apache.spark.repl.SparkILoop.createSparkContext(SparkILoop.scala:986)
	at $line3.$read$$iwC$$iwC.<init>(<console>:9)
	at $line3.$read$$iwC.<init>(<console>:18)
	at $line3.$read.<init>(<console>:20)
	at $line3.$read$.<init>(<console>:24)
	at $line3.$read$.<clinit>(<console>)
	at $line3.$eval$.<init>(<console>:7)
	at $line3.$eval$.<clinit>(<console>)
	at $line3.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:852)
	at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1125)
	at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:674)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:705)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:669)
	at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:828)
	at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:873)
	at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:785)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:123)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkIMain.beQuietDuring(SparkIMain.scala:270)
	at org.apache.spark.repl.SparkILoopInit$class.initializeSpark(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1$$anonfun$apply$mcZ$sp$5.apply$mcV$sp(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoopInit$class.runThunks(SparkILoopInit.scala:147)
	at org.apache.spark.repl.SparkILoop.runThunks(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoopInit$class.postInitialization(SparkILoopInit.scala:106)
	at org.apache.spark.repl.SparkILoop.postInitialization(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply$mcZ$sp(SparkILoop.scala:962)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1011)
	at org.apache.spark.repl.Main$.main(Main.scala:31)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:358)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
15/10/15 23:48:11 WARN component.AbstractLifeCycle: FAILED org.eclipse.jetty.server.Server@16e612cf: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:444)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:194)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1676)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1667)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:204)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:102)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:269)
	at org.apache.spark.repl.SparkILoop.createSparkContext(SparkILoop.scala:986)
	at $line3.$read$$iwC$$iwC.<init>(<console>:9)
	at $line3.$read$$iwC.<init>(<console>:18)
	at $line3.$read.<init>(<console>:20)
	at $line3.$read$.<init>(<console>:24)
	at $line3.$read$.<clinit>(<console>)
	at $line3.$eval$.<init>(<console>:7)
	at $line3.$eval$.<clinit>(<console>)
	at $line3.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:852)
	at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1125)
	at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:674)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:705)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:669)
	at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:828)
	at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:873)
	at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:785)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:123)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkIMain.beQuietDuring(SparkIMain.scala:270)
	at org.apache.spark.repl.SparkILoopInit$class.initializeSpark(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1$$anonfun$apply$mcZ$sp$5.apply$mcV$sp(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoopInit$class.runThunks(SparkILoopInit.scala:147)
	at org.apache.spark.repl.SparkILoop.runThunks(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoopInit$class.postInitialization(SparkILoopInit.scala:106)
	at org.apache.spark.repl.SparkILoop.postInitialization(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply$mcZ$sp(SparkILoop.scala:962)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1011)
	at org.apache.spark.repl.Main$.main(Main.scala:31)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:358)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/static,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/threadDump/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/threadDump,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/job/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/job,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs,null}
15/10/15 23:48:11 WARN util.Utils: Service 'SparkUI' could not bind on port 4049. Attempting port 4050.
15/10/15 23:48:11 INFO server.Server: jetty-8.y.z-SNAPSHOT
15/10/15 23:48:11 WARN component.AbstractLifeCycle: FAILED SelectChannelConnector@0.0.0.0:4050: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:444)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:194)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1676)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1667)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:204)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:102)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:269)
	at org.apache.spark.repl.SparkILoop.createSparkContext(SparkILoop.scala:986)
	at $line3.$read$$iwC$$iwC.<init>(<console>:9)
	at $line3.$read$$iwC.<init>(<console>:18)
	at $line3.$read.<init>(<console>:20)
	at $line3.$read$.<init>(<console>:24)
	at $line3.$read$.<clinit>(<console>)
	at $line3.$eval$.<init>(<console>:7)
	at $line3.$eval$.<clinit>(<console>)
	at $line3.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:852)
	at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1125)
	at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:674)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:705)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:669)
	at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:828)
	at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:873)
	at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:785)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:123)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkIMain.beQuietDuring(SparkIMain.scala:270)
	at org.apache.spark.repl.SparkILoopInit$class.initializeSpark(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1$$anonfun$apply$mcZ$sp$5.apply$mcV$sp(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoopInit$class.runThunks(SparkILoopInit.scala:147)
	at org.apache.spark.repl.SparkILoop.runThunks(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoopInit$class.postInitialization(SparkILoopInit.scala:106)
	at org.apache.spark.repl.SparkILoop.postInitialization(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply$mcZ$sp(SparkILoop.scala:962)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1011)
	at org.apache.spark.repl.Main$.main(Main.scala:31)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:358)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
15/10/15 23:48:11 WARN component.AbstractLifeCycle: FAILED org.eclipse.jetty.server.Server@3bb8fcb: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:444)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:194)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1676)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1667)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:204)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:102)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:269)
	at org.apache.spark.repl.SparkILoop.createSparkContext(SparkILoop.scala:986)
	at $line3.$read$$iwC$$iwC.<init>(<console>:9)
	at $line3.$read$$iwC.<init>(<console>:18)
	at $line3.$read.<init>(<console>:20)
	at $line3.$read$.<init>(<console>:24)
	at $line3.$read$.<clinit>(<console>)
	at $line3.$eval$.<init>(<console>:7)
	at $line3.$eval$.<clinit>(<console>)
	at $line3.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:852)
	at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1125)
	at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:674)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:705)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:669)
	at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:828)
	at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:873)
	at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:785)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:123)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkIMain.beQuietDuring(SparkIMain.scala:270)
	at org.apache.spark.repl.SparkILoopInit$class.initializeSpark(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1$$anonfun$apply$mcZ$sp$5.apply$mcV$sp(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoopInit$class.runThunks(SparkILoopInit.scala:147)
	at org.apache.spark.repl.SparkILoop.runThunks(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoopInit$class.postInitialization(SparkILoopInit.scala:106)
	at org.apache.spark.repl.SparkILoop.postInitialization(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply$mcZ$sp(SparkILoop.scala:962)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1011)
	at org.apache.spark.repl.Main$.main(Main.scala:31)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:358)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/static,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/threadDump/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/threadDump,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/job/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/job,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/json,null}
15/10/15 23:48:11 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs,null}
15/10/15 23:48:12 WARN util.Utils: Service 'SparkUI' could not bind on port 4050. Attempting port 4051.
15/10/15 23:48:12 INFO server.Server: jetty-8.y.z-SNAPSHOT
15/10/15 23:48:12 WARN component.AbstractLifeCycle: FAILED SelectChannelConnector@0.0.0.0:4051: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:444)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:194)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1676)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1667)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:204)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:102)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:269)
	at org.apache.spark.repl.SparkILoop.createSparkContext(SparkILoop.scala:986)
	at $line3.$read$$iwC$$iwC.<init>(<console>:9)
	at $line3.$read$$iwC.<init>(<console>:18)
	at $line3.$read.<init>(<console>:20)
	at $line3.$read$.<init>(<console>:24)
	at $line3.$read$.<clinit>(<console>)
	at $line3.$eval$.<init>(<console>:7)
	at $line3.$eval$.<clinit>(<console>)
	at $line3.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:852)
	at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1125)
	at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:674)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:705)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:669)
	at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:828)
	at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:873)
	at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:785)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:123)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkIMain.beQuietDuring(SparkIMain.scala:270)
	at org.apache.spark.repl.SparkILoopInit$class.initializeSpark(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1$$anonfun$apply$mcZ$sp$5.apply$mcV$sp(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoopInit$class.runThunks(SparkILoopInit.scala:147)
	at org.apache.spark.repl.SparkILoop.runThunks(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoopInit$class.postInitialization(SparkILoopInit.scala:106)
	at org.apache.spark.repl.SparkILoop.postInitialization(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply$mcZ$sp(SparkILoop.scala:962)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1011)
	at org.apache.spark.repl.Main$.main(Main.scala:31)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:358)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
15/10/15 23:48:12 WARN component.AbstractLifeCycle: FAILED org.eclipse.jetty.server.Server@640f1f0: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:444)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:194)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1676)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1667)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:204)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:102)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:269)
	at org.apache.spark.repl.SparkILoop.createSparkContext(SparkILoop.scala:986)
	at $line3.$read$$iwC$$iwC.<init>(<console>:9)
	at $line3.$read$$iwC.<init>(<console>:18)
	at $line3.$read.<init>(<console>:20)
	at $line3.$read$.<init>(<console>:24)
	at $line3.$read$.<clinit>(<console>)
	at $line3.$eval$.<init>(<console>:7)
	at $line3.$eval$.<clinit>(<console>)
	at $line3.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:852)
	at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1125)
	at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:674)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:705)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:669)
	at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:828)
	at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:873)
	at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:785)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:123)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkIMain.beQuietDuring(SparkIMain.scala:270)
	at org.apache.spark.repl.SparkILoopInit$class.initializeSpark(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1$$anonfun$apply$mcZ$sp$5.apply$mcV$sp(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoopInit$class.runThunks(SparkILoopInit.scala:147)
	at org.apache.spark.repl.SparkILoop.runThunks(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoopInit$class.postInitialization(SparkILoopInit.scala:106)
	at org.apache.spark.repl.SparkILoop.postInitialization(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply$mcZ$sp(SparkILoop.scala:962)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1011)
	at org.apache.spark.repl.Main$.main(Main.scala:31)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:358)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
15/10/15 23:48:12 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
15/10/15 23:48:12 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/,null}
15/10/15 23:48:12 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/static,null}
15/10/15 23:48:12 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/threadDump/json,null}
15/10/15 23:48:12 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/threadDump,null}
15/10/15 23:48:12 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/json,null}
15/10/15 23:48:12 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors,null}
15/10/15 23:48:12 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment/json,null}
15/10/15 23:48:12 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment,null}
15/10/15 23:48:12 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
15/10/15 23:48:12 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
15/10/15 23:48:12 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/json,null}
15/10/15 23:48:12 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage,null}
15/10/15 23:48:12 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
15/10/15 23:48:12 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
15/10/15 23:48:12 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
15/10/15 23:48:12 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
15/10/15 23:48:12 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/json,null}
15/10/15 23:48:12 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages,null}
15/10/15 23:48:12 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/job/json,null}
15/10/15 23:48:12 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/job,null}
15/10/15 23:48:12 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/json,null}
15/10/15 23:48:12 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs,null}
15/10/15 23:48:12 WARN util.Utils: Service 'SparkUI' could not bind on port 4051. Attempting port 4052.
15/10/15 23:48:12 INFO server.Server: jetty-8.y.z-SNAPSHOT
15/10/15 23:48:12 WARN component.AbstractLifeCycle: FAILED SelectChannelConnector@0.0.0.0:4052: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:444)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:194)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1676)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1667)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:204)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:102)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:269)
	at org.apache.spark.repl.SparkILoop.createSparkContext(SparkILoop.scala:986)
	at $line3.$read$$iwC$$iwC.<init>(<console>:9)
	at $line3.$read$$iwC.<init>(<console>:18)
	at $line3.$read.<init>(<console>:20)
	at $line3.$read$.<init>(<console>:24)
	at $line3.$read$.<clinit>(<console>)
	at $line3.$eval$.<init>(<console>:7)
	at $line3.$eval$.<clinit>(<console>)
	at $line3.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:852)
	at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1125)
	at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:674)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:705)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:669)
	at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:828)
	at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:873)
	at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:785)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:123)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkIMain.beQuietDuring(SparkIMain.scala:270)
	at org.apache.spark.repl.SparkILoopInit$class.initializeSpark(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1$$anonfun$apply$mcZ$sp$5.apply$mcV$sp(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoopInit$class.runThunks(SparkILoopInit.scala:147)
	at org.apache.spark.repl.SparkILoop.runThunks(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoopInit$class.postInitialization(SparkILoopInit.scala:106)
	at org.apache.spark.repl.SparkILoop.postInitialization(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply$mcZ$sp(SparkILoop.scala:962)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1011)
	at org.apache.spark.repl.Main$.main(Main.scala:31)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:358)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
15/10/15 23:48:12 WARN component.AbstractLifeCycle: FAILED org.eclipse.jetty.server.Server@38ae264a: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:444)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:194)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1676)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1667)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:204)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:102)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:269)
	at org.apache.spark.repl.SparkILoop.createSparkContext(SparkILoop.scala:986)
	at $line3.$read$$iwC$$iwC.<init>(<console>:9)
	at $line3.$read$$iwC.<init>(<console>:18)
	at $line3.$read.<init>(<console>:20)
	at $line3.$read$.<init>(<console>:24)
	at $line3.$read$.<clinit>(<console>)
	at $line3.$eval$.<init>(<console>:7)
	at $line3.$eval$.<clinit>(<console>)
	at $line3.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:852)
	at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1125)
	at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:674)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:705)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:669)
	at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:828)
	at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:873)
	at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:785)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:123)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkIMain.beQuietDuring(SparkIMain.scala:270)
	at org.apache.spark.repl.SparkILoopInit$class.initializeSpark(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1$$anonfun$apply$mcZ$sp$5.apply$mcV$sp(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoopInit$class.runThunks(SparkILoopInit.scala:147)
	at org.apache.spark.repl.SparkILoop.runThunks(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoopInit$class.postInitialization(SparkILoopInit.scala:106)
	at org.apache.spark.repl.SparkILoop.postInitialization(SparkILoop.scala:60)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply$mcZ$sp(SparkILoop.scala:962)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
	at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:916)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1011)
	at org.apache.spark.repl.Main$.main(Main.scala:31)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:358)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
15/10/15 23:48:12 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
15/10/15 23:48:12 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/,null}
15/10/15 23:48:12 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/static,null}
15/10/15 23:48:12 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/threadDump/json,null}
15/10/15 23:48:12 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/threadDump,null}
15/10/15 23:48:12 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/json,null}
15/10/15 23:48:12 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors,null}
15/10/15 23:48:12 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment/json,null}
15/10/15 23:48:12 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment,null}
15/10/15 23:48:12 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
15/10/15 23:48:12 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
15/10/15 23:48:12 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/json,null}
15/10/15 23:48:12 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage,null}
15/10/15 23:48:12 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
15/10/15 23:48:12 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
15/10/15 23:48:12 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
15/10/15 23:48:12 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
15/10/15 23:48:12 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/json,null}
15/10/15 23:48:12 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages,null}
15/10/15 23:48:12 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/job/json,null}
15/10/15 23:48:12 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/job,null}
15/10/15 23:48:12 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/json,null}
15/10/15 23:48:12 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs,null}
15/10/15 23:48:12 WARN util.Utils: Service 'SparkUI' could not bind on port 4052. Attempting port 4053.
15/10/15 23:48:12 INFO server.Server: jetty-8.y.z-SNAPSHOT
15/10/15 23:48:12 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:4053
15/10/15 23:48:12 INFO util.Utils: Successfully started service 'SparkUI' on port 4053.
15/10/15 23:48:12 INFO ui.SparkUI: Started SparkUI at http://cs6360.utdallas.edu:4053
15/10/15 23:48:12 INFO client.RMProxy: Connecting to ResourceManager at cshadoop1.utdallas.edu/10.176.92.71:8032
15/10/15 23:48:12 INFO yarn.Client: Requesting a new application from cluster with 8 NodeManagers
15/10/15 23:48:12 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (8192 MB per container)
15/10/15 23:48:12 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
15/10/15 23:48:12 INFO yarn.Client: Setting up container launch context for our AM
15/10/15 23:48:12 INFO yarn.Client: Preparing resources for our AM container
15/10/15 23:48:13 INFO yarn.Client: Uploading resource file:/usr/local/spark-1.2.0-bin-hadoop2.4/lib/spark-assembly-1.2.0-hadoop2.4.0.jar -> hdfs://cshadoop1/user/kxk140230/.sparkStaging/application_1444046496659_0736/spark-assembly-1.2.0-hadoop2.4.0.jar
15/10/15 23:48:15 INFO yarn.Client: Setting up the launch environment for our AM container
15/10/15 23:48:16 INFO spark.SecurityManager: Changing view acls to: kxk140230
15/10/15 23:48:16 INFO spark.SecurityManager: Changing modify acls to: kxk140230
15/10/15 23:48:16 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(kxk140230); users with modify permissions: Set(kxk140230)
15/10/15 23:48:16 INFO yarn.Client: Submitting application 736 to ResourceManager
15/10/15 23:48:16 INFO impl.YarnClientImpl: Submitted application application_1444046496659_0736
15/10/15 23:48:17 INFO yarn.Client: Application report for application_1444046496659_0736 (state: ACCEPTED)
15/10/15 23:48:17 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1444970896012
	 final status: UNDEFINED
	 tracking URL: http://cshadoop1.utdallas.edu:8088/proxy/application_1444046496659_0736/
	 user: kxk140230
15/10/15 23:48:18 INFO yarn.Client: Application report for application_1444046496659_0736 (state: ACCEPTED)
15/10/15 23:48:19 INFO yarn.Client: Application report for application_1444046496659_0736 (state: ACCEPTED)
15/10/15 23:48:20 INFO yarn.Client: Application report for application_1444046496659_0736 (state: ACCEPTED)
15/10/15 23:48:21 INFO yarn.Client: Application report for application_1444046496659_0736 (state: ACCEPTED)
15/10/15 23:48:21 INFO cluster.YarnClientSchedulerBackend: ApplicationMaster registered as Actor[akka.tcp://sparkYarnAM@cshadoop2.utdallas.edu:46020/user/YarnAM#-1102557264]
15/10/15 23:48:21 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> cshadoop1.utdallas.edu, PROXY_URI_BASES -> http://cshadoop1.utdallas.edu:8088/proxy/application_1444046496659_0736), /proxy/application_1444046496659_0736
15/10/15 23:48:21 INFO ui.JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
15/10/15 23:48:22 INFO yarn.Client: Application report for application_1444046496659_0736 (state: RUNNING)
15/10/15 23:48:22 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: cshadoop2.utdallas.edu
	 ApplicationMaster RPC port: 0
	 queue: default
	 start time: 1444970896012
	 final status: UNDEFINED
	 tracking URL: http://cshadoop1.utdallas.edu:8088/proxy/application_1444046496659_0736/
	 user: kxk140230
15/10/15 23:48:22 INFO cluster.YarnClientSchedulerBackend: Application application_1444046496659_0736 has started running.
15/10/15 23:48:22 INFO netty.NettyBlockTransferService: Server created on 60352
15/10/15 23:48:22 INFO storage.BlockManagerMaster: Trying to register BlockManager
15/10/15 23:48:22 INFO storage.BlockManagerMasterActor: Registering block manager cs6360.utdallas.edu:60352 with 265.4 MB RAM, BlockManagerId(<driver>, cs6360.utdallas.edu, 60352)
15/10/15 23:48:22 INFO storage.BlockManagerMaster: Registered BlockManager
15/10/15 23:48:29 INFO cluster.YarnClientSchedulerBackend: Registered executor: Actor[akka.tcp://sparkExecutor@cshadoop2.utdallas.edu:47255/user/Executor#1570857616] with ID 5
15/10/15 23:48:29 INFO util.RackResolver: Resolved cshadoop2.utdallas.edu to /default-rack
15/10/15 23:48:30 INFO storage.BlockManagerMasterActor: Registering block manager cshadoop2.utdallas.edu:45718 with 1060.3 MB RAM, BlockManagerId(5, cshadoop2.utdallas.edu, 45718)
15/10/15 23:48:30 INFO cluster.YarnClientSchedulerBackend: Registered executor: Actor[akka.tcp://sparkExecutor@cshadoop4.utdallas.edu:33225/user/Executor#-52034148] with ID 1
15/10/15 23:48:30 INFO util.RackResolver: Resolved cshadoop4.utdallas.edu to /default-rack
15/10/15 23:48:30 INFO storage.BlockManagerMasterActor: Registering block manager cshadoop4.utdallas.edu:37141 with 1060.3 MB RAM, BlockManagerId(1, cshadoop4.utdallas.edu, 37141)
15/10/15 23:48:31 INFO cluster.YarnClientSchedulerBackend: Registered executor: Actor[akka.tcp://sparkExecutor@cshadoop9.utdallas.edu:48775/user/Executor#-1648602730] with ID 2
15/10/15 23:48:31 INFO util.RackResolver: Resolved cshadoop9.utdallas.edu to /default-rack
15/10/15 23:48:32 INFO storage.BlockManagerMasterActor: Registering block manager cshadoop9.utdallas.edu:48561 with 1060.3 MB RAM, BlockManagerId(2, cshadoop9.utdallas.edu, 48561)
15/10/15 23:48:32 INFO cluster.YarnClientSchedulerBackend: Registered executor: Actor[akka.tcp://sparkExecutor@cshadoop8.utdallas.edu:53739/user/Executor#412366293] with ID 4
15/10/15 23:48:32 INFO util.RackResolver: Resolved cshadoop8.utdallas.edu to /default-rack
15/10/15 23:48:32 INFO cluster.YarnClientSchedulerBackend: Registered executor: Actor[akka.tcp://sparkExecutor@cshadoop3.utdallas.edu:55930/user/Executor#1040978273] with ID 3
15/10/15 23:48:32 INFO util.RackResolver: Resolved cshadoop3.utdallas.edu to /default-rack
15/10/15 23:48:32 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8
15/10/15 23:48:33 INFO repl.SparkILoop: Created spark context..
Spark context available as sc.
15/10/15 23:48:33 INFO storage.BlockManagerMasterActor: Registering block manager cshadoop8.utdallas.edu:49001 with 1060.3 MB RAM, BlockManagerId(4, cshadoop8.utdallas.edu, 49001)

scala> 15/10/15 23:48:33 INFO storage.BlockManagerMasterActor: Registering block manager cshadoop3.utdallas.edu:57751 with 1060.3 MB RAM, BlockManagerId(3, cshadoop3.utdallas.edu, 57751)
15/10/15 23:48:34 INFO cluster.YarnClientSchedulerBackend: Registered executor: Actor[akka.tcp://sparkExecutor@cshadoop7.utdallas.edu:50836/user/Executor#639004957] with ID 6
15/10/15 23:48:34 INFO util.RackResolver: Resolved cshadoop7.utdallas.edu to /default-rack
15/10/15 23:48:34 INFO storage.BlockManagerMasterActor: Registering block manager cshadoop7.utdallas.edu:41357 with 1060.3 MB RAM, BlockManagerId(6, cshadoop7.utdallas.edu, 41357)
m

scala> scala> var reviewFile = sc.textFile("/yelpdatafall/review/review.csv")

// Detected repl transcript paste: ctrl-D to finish.


scala> def myAvgFunc[T]( a: Iterable[T] )( implicit num: Numeric[T] ) = {
     |    num.toDouble( a.sum ) / a.size
     | }

scala> var ab  = reviewFile.map(l => l.split("\\^")).map(l => (l(2),l(3).toDouble)).groupByKey()

scala> val kx = ab.map(l => (l._1, myAvgFunc (l._2))).sortByKey()

scala> val finalOP = kx.map(l => (l._2, l._1)). top(10).foreach(println)

a
// Replaying 5 commands from transcript.

scala> var reviewFile = sc.textFile("/yelpdatafall/review/review.csv")
15/10/15 23:50:15 INFO storage.MemoryStore: ensureFreeSpace(217490) called with curMem=0, maxMem=278302556
15/10/15 23:50:15 INFO storage.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 212.4 KB, free 265.2 MB)
15/10/15 23:50:15 INFO storage.MemoryStore: ensureFreeSpace(31976) called with curMem=217490, maxMem=278302556
15/10/15 23:50:15 INFO storage.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 31.2 KB, free 265.2 MB)
15/10/15 23:50:15 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on cs6360.utdallas.edu:60352 (size: 31.2 KB, free: 265.4 MB)
15/10/15 23:50:15 INFO storage.BlockManagerMaster: Updated info of block broadcast_0_piece0
15/10/15 23:50:15 INFO spark.SparkContext: Created broadcast 0 from textFile at <console>:12
reviewFile: org.apache.spark.rdd.RDD[String] = /yelpdatafall/review/review.csv MappedRDD[1] at textFile at <console>:12

scala> def myAvgFunc[T]( a: Iterable[T] )( implicit num: Numeric[T] ) = {
   num.toDouble( a.sum ) / a.size
}
myAvgFunc: [T](a: Iterable[T])(implicit num: Numeric[T])Double

scala> var ab  = reviewFile.map(l => l.split("\\^")).map(l => (l(2),l(3).toDouble)).groupByKey()
15/10/15 23:50:17 INFO mapred.FileInputFormat: Total input paths to process : 1
ab: org.apache.spark.rdd.RDD[(String, Iterable[Double])] = ShuffledRDD[4] at groupByKey at <console>:14

scala> val kx = ab.map(l => (l._1, myAvgFunc (l._2))).sortByKey()
15/10/15 23:50:18 INFO spark.SparkContext: Starting job: sortByKey at <console>:18
15/10/15 23:50:18 INFO scheduler.DAGScheduler: Registering RDD 3 (map at <console>:14)
15/10/15 23:50:18 INFO scheduler.DAGScheduler: Got job 0 (sortByKey at <console>:18) with 2 output partitions (allowLocal=false)
15/10/15 23:50:18 INFO scheduler.DAGScheduler: Final stage: Stage 1(sortByKey at <console>:18)
15/10/15 23:50:18 INFO scheduler.DAGScheduler: Parents of final stage: List(Stage 0)
15/10/15 23:50:18 INFO scheduler.DAGScheduler: Missing parents: List(Stage 0)
15/10/15 23:50:18 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[3] at map at <console>:14), which has no missing parents
15/10/15 23:50:18 INFO storage.MemoryStore: ensureFreeSpace(3568) called with curMem=249466, maxMem=278302556
15/10/15 23:50:18 INFO storage.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 3.5 KB, free 265.2 MB)
15/10/15 23:50:18 INFO storage.MemoryStore: ensureFreeSpace(2521) called with curMem=253034, maxMem=278302556
15/10/15 23:50:18 INFO storage.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.5 KB, free 265.2 MB)
15/10/15 23:50:18 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on cs6360.utdallas.edu:60352 (size: 2.5 KB, free: 265.4 MB)
15/10/15 23:50:18 INFO storage.BlockManagerMaster: Updated info of block broadcast_1_piece0
15/10/15 23:50:18 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:838
15/10/15 23:50:18 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from Stage 0 (MappedRDD[3] at map at <console>:14)
15/10/15 23:50:18 INFO cluster.YarnClientClusterScheduler: Adding task set 0.0 with 2 tasks
15/10/15 23:50:18 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, cshadoop8.utdallas.edu, NODE_LOCAL, 1300 bytes)
15/10/15 23:50:18 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, cshadoop8.utdallas.edu, NODE_LOCAL, 1300 bytes)
15/10/15 23:50:19 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on cshadoop8.utdallas.edu:49001 (size: 2.5 KB, free: 1060.3 MB)
15/10/15 23:50:19 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on cshadoop8.utdallas.edu:49001 (size: 31.2 KB, free: 1060.3 MB)
15/10/15 23:50:20 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2171 ms on cshadoop8.utdallas.edu (1/2)
15/10/15 23:50:20 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 2182 ms on cshadoop8.utdallas.edu (2/2)
15/10/15 23:50:20 INFO scheduler.DAGScheduler: Stage 0 (map at <console>:14) finished in 2.190 s
15/10/15 23:50:20 INFO cluster.YarnClientClusterScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool 
15/10/15 23:50:20 INFO scheduler.DAGScheduler: looking for newly runnable stages
15/10/15 23:50:20 INFO scheduler.DAGScheduler: running: Set()
15/10/15 23:50:20 INFO scheduler.DAGScheduler: waiting: Set(Stage 1)
15/10/15 23:50:20 INFO scheduler.DAGScheduler: failed: Set()
15/10/15 23:50:20 INFO scheduler.DAGScheduler: Missing parents for Stage 1: List()
15/10/15 23:50:20 INFO scheduler.DAGScheduler: Submitting Stage 1 (MapPartitionsRDD[7] at sortByKey at <console>:18), which is now runnable
15/10/15 23:50:20 INFO storage.MemoryStore: ensureFreeSpace(6424) called with curMem=255555, maxMem=278302556
15/10/15 23:50:20 INFO storage.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 6.3 KB, free 265.2 MB)
15/10/15 23:50:20 INFO storage.MemoryStore: ensureFreeSpace(4172) called with curMem=261979, maxMem=278302556
15/10/15 23:50:20 INFO storage.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.1 KB, free 265.2 MB)
15/10/15 23:50:20 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on cs6360.utdallas.edu:60352 (size: 4.1 KB, free: 265.4 MB)
15/10/15 23:50:20 INFO storage.BlockManagerMaster: Updated info of block broadcast_2_piece0
15/10/15 23:50:20 INFO spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:838
15/10/15 23:50:20 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from Stage 1 (MapPartitionsRDD[7] at sortByKey at <console>:18)
15/10/15 23:50:20 INFO cluster.YarnClientClusterScheduler: Adding task set 1.0 with 2 tasks
15/10/15 23:50:20 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, cshadoop9.utdallas.edu, PROCESS_LOCAL, 1056 bytes)
15/10/15 23:50:20 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, cshadoop3.utdallas.edu, PROCESS_LOCAL, 1056 bytes)
15/10/15 23:50:21 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on cshadoop3.utdallas.edu:57751 (size: 4.1 KB, free: 1060.3 MB)
15/10/15 23:50:21 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on cshadoop9.utdallas.edu:48561 (size: 4.1 KB, free: 1060.3 MB)
15/10/15 23:50:21 INFO spark.MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 0 to sparkExecutor@cshadoop3.utdallas.edu:55930
15/10/15 23:50:21 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 159 bytes
15/10/15 23:50:21 INFO spark.MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 0 to sparkExecutor@cshadoop9.utdallas.edu:48775
15/10/15 23:50:22 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 1692 ms on cshadoop9.utdallas.edu (1/2)
15/10/15 23:50:22 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 1709 ms on cshadoop3.utdallas.edu (2/2)
15/10/15 23:50:22 INFO scheduler.DAGScheduler: Stage 1 (sortByKey at <console>:18) finished in 1.715 s
15/10/15 23:50:22 INFO cluster.YarnClientClusterScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool 
15/10/15 23:50:22 INFO scheduler.DAGScheduler: Job 0 finished: sortByKey at <console>:18, took 4.145922 s
kx: org.apache.spark.rdd.RDD[(String, Double)] = ShuffledRDD[8] at sortByKey at <console>:18

scala> val finalOP = kx.map(l => (l._2, l._1)). top(10).foreach(println)
15/10/15 23:50:23 INFO spark.SparkContext: Starting job: top at <console>:20
15/10/15 23:50:23 INFO scheduler.DAGScheduler: Registering RDD 5 (map at <console>:18)
15/10/15 23:50:23 INFO scheduler.DAGScheduler: Got job 1 (top at <console>:20) with 2 output partitions (allowLocal=false)
15/10/15 23:50:23 INFO scheduler.DAGScheduler: Final stage: Stage 4(top at <console>:20)
15/10/15 23:50:23 INFO scheduler.DAGScheduler: Parents of final stage: List(Stage 3)
15/10/15 23:50:23 INFO scheduler.DAGScheduler: Missing parents: List(Stage 3)
15/10/15 23:50:23 INFO scheduler.DAGScheduler: Submitting Stage 3 (MappedRDD[5] at map at <console>:18), which has no missing parents
15/10/15 23:50:23 INFO storage.MemoryStore: ensureFreeSpace(6472) called with curMem=266151, maxMem=278302556
15/10/15 23:50:23 INFO storage.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.3 KB, free 265.2 MB)
15/10/15 23:50:23 INFO storage.MemoryStore: ensureFreeSpace(4239) called with curMem=272623, maxMem=278302556
15/10/15 23:50:23 INFO storage.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 4.1 KB, free 265.1 MB)
15/10/15 23:50:23 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on cs6360.utdallas.edu:60352 (size: 4.1 KB, free: 265.4 MB)
15/10/15 23:50:23 INFO storage.BlockManagerMaster: Updated info of block broadcast_3_piece0
15/10/15 23:50:23 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:838
15/10/15 23:50:23 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from Stage 3 (MappedRDD[5] at map at <console>:18)
15/10/15 23:50:23 INFO cluster.YarnClientClusterScheduler: Adding task set 3.0 with 2 tasks
15/10/15 23:50:23 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 3.0 (TID 4, cshadoop9.utdallas.edu, PROCESS_LOCAL, 1045 bytes)
15/10/15 23:50:23 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 3.0 (TID 5, cshadoop7.utdallas.edu, PROCESS_LOCAL, 1045 bytes)
15/10/15 23:50:23 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on cshadoop9.utdallas.edu:48561 (size: 4.1 KB, free: 1060.3 MB)
15/10/15 23:50:23 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on cshadoop7.utdallas.edu:41357 (size: 4.1 KB, free: 1060.3 MB)
15/10/15 23:50:24 INFO spark.MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 0 to sparkExecutor@cshadoop7.utdallas.edu:50836
15/10/15 23:50:24 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 3.0 (TID 4) in 873 ms on cshadoop9.utdallas.edu (1/2)
15/10/15 23:50:25 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 3.0 (TID 5) in 2369 ms on cshadoop7.utdallas.edu (2/2)
15/10/15 23:50:25 INFO scheduler.DAGScheduler: Stage 3 (map at <console>:18) finished in 2.373 s
15/10/15 23:50:25 INFO scheduler.DAGScheduler: looking for newly runnable stages
15/10/15 23:50:25 INFO cluster.YarnClientClusterScheduler: Removed TaskSet 3.0, whose tasks have all completed, from pool 
15/10/15 23:50:25 INFO scheduler.DAGScheduler: running: Set()
15/10/15 23:50:25 INFO scheduler.DAGScheduler: waiting: Set(Stage 4)
15/10/15 23:50:25 INFO scheduler.DAGScheduler: failed: Set()
15/10/15 23:50:25 INFO scheduler.DAGScheduler: Missing parents for Stage 4: List()
15/10/15 23:50:25 INFO scheduler.DAGScheduler: Submitting Stage 4 (MapPartitionsRDD[10] at top at <console>:20), which is now runnable
15/10/15 23:50:25 INFO storage.MemoryStore: ensureFreeSpace(3376) called with curMem=276862, maxMem=278302556
15/10/15 23:50:25 INFO storage.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 3.3 KB, free 265.1 MB)
15/10/15 23:50:26 INFO storage.MemoryStore: ensureFreeSpace(2395) called with curMem=280238, maxMem=278302556
15/10/15 23:50:26 INFO storage.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.3 KB, free 265.1 MB)
15/10/15 23:50:26 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on cs6360.utdallas.edu:60352 (size: 2.3 KB, free: 265.4 MB)
15/10/15 23:50:26 INFO storage.BlockManagerMaster: Updated info of block broadcast_4_piece0
15/10/15 23:50:26 INFO spark.SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:838
15/10/15 23:50:26 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from Stage 4 (MapPartitionsRDD[10] at top at <console>:20)
15/10/15 23:50:26 INFO cluster.YarnClientClusterScheduler: Adding task set 4.0 with 2 tasks
15/10/15 23:50:26 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, cshadoop9.utdallas.edu, PROCESS_LOCAL, 1056 bytes)
15/10/15 23:50:26 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, cshadoop8.utdallas.edu, PROCESS_LOCAL, 1056 bytes)
15/10/15 23:50:26 INFO storage.BlockManager: Removing broadcast 2
15/10/15 23:50:26 INFO storage.BlockManager: Removing block broadcast_2
15/10/15 23:50:26 INFO storage.MemoryStore: Block broadcast_2 of size 6424 dropped from memory (free 278026347)
15/10/15 23:50:26 INFO storage.BlockManager: Removing block broadcast_2_piece0
15/10/15 23:50:26 INFO storage.MemoryStore: Block broadcast_2_piece0 of size 4172 dropped from memory (free 278030519)
15/10/15 23:50:26 INFO storage.BlockManagerInfo: Removed broadcast_2_piece0 on cs6360.utdallas.edu:60352 in memory (size: 4.1 KB, free: 265.4 MB)
15/10/15 23:50:26 INFO storage.BlockManagerMaster: Updated info of block broadcast_2_piece0
15/10/15 23:50:26 INFO storage.BlockManagerInfo: Removed broadcast_2_piece0 on cshadoop9.utdallas.edu:48561 in memory (size: 4.1 KB, free: 1060.3 MB)
15/10/15 23:50:26 INFO storage.BlockManagerInfo: Removed broadcast_2_piece0 on cshadoop3.utdallas.edu:57751 in memory (size: 4.1 KB, free: 1060.3 MB)
15/10/15 23:50:26 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on cshadoop9.utdallas.edu:48561 (size: 2.3 KB, free: 1060.3 MB)
15/10/15 23:50:26 INFO spark.ContextCleaner: Cleaned broadcast 2
15/10/15 23:50:26 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on cshadoop8.utdallas.edu:49001 (size: 2.3 KB, free: 1060.3 MB)
15/10/15 23:50:26 INFO spark.MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 1 to sparkExecutor@cshadoop9.utdallas.edu:48775
15/10/15 23:50:26 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 169 bytes
15/10/15 23:50:26 INFO spark.MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 1 to sparkExecutor@cshadoop8.utdallas.edu:53739
15/10/15 23:50:26 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 378 ms on cshadoop9.utdallas.edu (1/2)
15/10/15 23:50:26 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 717 ms on cshadoop8.utdallas.edu (2/2)
15/10/15 23:50:26 INFO cluster.YarnClientClusterScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool 
15/10/15 23:50:26 INFO scheduler.DAGScheduler: Stage 4 (top at <console>:20) finished in 0.725 s
15/10/15 23:50:26 INFO scheduler.DAGScheduler: Job 1 finished: top at <console>:20, took 4.207268 s
(5.0,zx1lLUvlRUN5nQlSj3HRDw)
(5.0,zweAzZDJ8SfwUID1UEGkbA)
(5.0,zvo21oKr656PQNVblYxYlg)
(5.0,ztswDToyZGyL_dxo0CEQew)
(5.0,zrmO-d-Mw3kv9dWa7Trr9Q)
(5.0,zqZjrcTf9Bc7r_VLGN4mrw)
(5.0,zkD9AtBT9ZkLFiV31gvEGw)
(5.0,ziS_fZ7Z99fa4qNVr879vg)
(5.0,zh2Eja5h54vM7GUibHoi9A)
(5.0,zh-MNFY4TyG7x2itUVlESQ)
finalOP: Unit = ()


scala> 
